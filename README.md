# ğŸ§  Named Entity Recognition (NER) with Transformers

This implementation of **Named Entity Recognition (NER)** using modern **Transformer-based architectures** like BERT! This project demonstrates how to extract entities such as names, organizations, locations, and more from natural language text using deep learning. ğŸ“ŠğŸ“š

## ğŸš€ Project Highlights

- ğŸ¤– Built using **HuggingFace Transformers**
- ğŸ·ï¸ Supports custom tagging schemes (BIO, BILOU)
- ğŸ”¬ Fine-tuned for **NER tasks** with token-level classification
- ğŸ“ˆ Visualization of predictions on sample inputs
- ğŸ“ Modular and reusable Jupyter Notebook

---

## ğŸ§© What is NER?

**Named Entity Recognition (NER)** is a subtask of Information Extraction that classifies named entities into predefined categories such as:

- ğŸ“ **Location** (e.g., "Paris", "India")
- ğŸ‘¤ **Person** (e.g., "Albert Einstein")
- ğŸ¢ **Organization** (e.g., "Google", "UN")
- ğŸ—“ï¸ **Date/Time** (e.g., "March 26th", "2025")

---


